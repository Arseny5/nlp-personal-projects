# 10 projects with architecture Transformer for NLP tasks
![image](transformers.png)

### Implemented projects
1) [Implementation transformer model](https://github.com/Arseny5/nlp-personal-projects/tree/main/01-implement-vanilla-transformer):
   - Implementation vanilla transformer from encoder-decoder classes to positional encoding, self-attention, multi-head attention, feed-forward network, residual connections and layer normalization.
   - Using [WMT 2014](https://huggingface.co/datasets/wmt14) English-German and English-French datasets solve text translation problem.
   - Analyze Label Smoothing in transformer classification using KLDiv loss.
   - Using [Tatoeba Russian-English](https://huggingface.co/datasets/tatoeba) dataset solve text translation problem.
3) [BERT analyzing](https://github.com/Arseny5/nlp-personal-projects/tree/main/03-bert-for-NER)
4) [Using rubert-tiny2 work with NER-problem on Russian Drug Reaction Corpus](https://github.com/Arseny5/nlp-personal-projects/tree/main/03-bert-for-NER)
5) [GPT2 generation with different strategies](https://github.com/Arseny5/nlp-personal-projects/tree/main/03-bert-for-NER)
