# 10 projects with architecture Transformer for NLP tasks
![image](transformers.png)

### Implemented projects
1) [Vanilla Transformer](https://github.com/Arseny5/nlp-personal-projects/tree/main/01-implement-vanilla-transformer):
   - Theoretical and implementaion vanilla transforemer from encoder-decoder classes to positional encoding, self-attention, multi-head attention, residual connections and layer normalization.
   - Using WMT 2014 English-German and English-French datasets solve text translation problem.
   - Analyze Label Smoothing in transformer classification using KLDiv loss.
   - Using Tatoeba Russian-English dataset solve text translation problem.
3) [BERT analyzing](https://github.com/Arseny5/nlp-personal-projects/tree/main/03-bert-for-NER)
4) [Using rubert-tiny2 work with NER-problem on Russian Drug Reaction Corpus](https://github.com/Arseny5/nlp-personal-projects/tree/main/03-bert-for-NER)
5) [GPT2 generation with different strategies](https://github.com/Arseny5/nlp-personal-projects/tree/main/03-bert-for-NER)
